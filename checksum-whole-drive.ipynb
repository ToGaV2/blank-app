{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea8eb222",
   "metadata": {
    "papermill": {
     "duration": 0.003302,
     "end_time": "2024-11-06T10:55:07.421228",
     "exception": false,
     "start_time": "2024-11-06T10:55:07.417926",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Use Python to Generate Checksums \n",
    "Presented with a whole directory of files, how would one generate checksums for each file, AND maintain the filestructure in a format conducive to subsequently compare the manifest and then download only the appropriate files?\n",
    "\n",
    "This function, with 4 common libraries, shows how to checksum 1490 files in under 3 seconds. We then output a pair of lists generated into a pandas data frame, and then save that dataframe as a CSV for further use.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa4ce379",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-06T10:55:07.428932Z",
     "iopub.status.busy": "2024-11-06T10:55:07.428483Z",
     "iopub.status.idle": "2024-11-06T10:55:18.015184Z",
     "shell.execute_reply": "2024-11-06T10:55:18.013880Z"
    },
    "papermill": {
     "duration": 10.593673,
     "end_time": "2024-11-06T10:55:18.017808",
     "exception": false,
     "start_time": "2024-11-06T10:55:07.424135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration in Seconds:  0:00:09.467912\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import hashlib\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "\n",
    "def generate_checksums(directory):\n",
    "    s = datetime.datetime.now()\n",
    "    i = 0\n",
    "    filer = []\n",
    "    output = []\n",
    "    \"\"\"Generates checksums for all files in a directory and its subdirectories.\"\"\"\n",
    "\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            filepath = os.path.join(root, file)\n",
    "\n",
    "            # Calculate the checksum (using SHA-256 in this example)\n",
    "            hasher = hashlib.sha256()\n",
    "            with open(filepath, 'rb') as f:\n",
    "                while True:\n",
    "                    chunk = f.read(10000000000)  # Read file in chunks\n",
    "                    if not chunk:\n",
    "                        break\n",
    "                    hasher.update(chunk)\n",
    "                    filer.append(filepath)\n",
    "                    output.append(hasher.hexdigest())\n",
    "                    \n",
    "            #print(f\"{filepath}: {hasher.hexdigest()}\")\n",
    "    print(\"Duration in Seconds: \", datetime.datetime.now()-s)\n",
    "    return pd.DataFrame({'filename':filer, 'hashs':output})\n",
    "if __name__ == \"__main__\":\n",
    "    directory_to_scan = \"/kaggle/input/traffic-signs-dataset-in-yolo-format\"\n",
    "    f = generate_checksums(directory_to_scan)\n",
    "    f.to_csv('fileout.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7112fee5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T10:55:18.026008Z",
     "iopub.status.busy": "2024-11-06T10:55:18.024911Z",
     "iopub.status.idle": "2024-11-06T10:55:18.033540Z",
     "shell.execute_reply": "2024-11-06T10:55:18.032500Z"
    },
    "papermill": {
     "duration": 0.015275,
     "end_time": "2024-11-06T10:55:18.035988",
     "exception": false,
     "start_time": "2024-11-06T10:55:18.020713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1490"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see how many files were processed\n",
    "f.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e1ad7fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T10:55:18.043857Z",
     "iopub.status.busy": "2024-11-06T10:55:18.043471Z",
     "iopub.status.idle": "2024-11-06T10:55:19.194516Z",
     "shell.execute_reply": "2024-11-06T10:55:19.193219Z"
    },
    "papermill": {
     "duration": 1.158376,
     "end_time": "2024-11-06T10:55:19.197523",
     "exception": false,
     "start_time": "2024-11-06T10:55:18.039147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ",filename,hashs\r\n",
      "0,/kaggle/input/traffic-signs-dataset-in-yolo-format/yolov3_ts_train.cfg,cdf1f1d65f81875e3378fc4de80a97b61f066dc955bf67a320dc022f3b503388\r\n",
      "1,/kaggle/input/traffic-signs-dataset-in-yolo-format/getting-full-path.py,4cd280a8e57e25736ff01d0238f96bcbe985c1fb0ff30df745c35ec01f43e215\r\n",
      "2,/kaggle/input/traffic-signs-dataset-in-yolo-format/test.txt,e6b24c8f74469a4ad790f6b136540fa4bc38e4be0b695fac0c9159587fa1a6c9\r\n",
      "3,/kaggle/input/traffic-signs-dataset-in-yolo-format/ts_data.data,4082abba3abea1765ce1817154b6344b61e89af09424a290be295123b576b32e\r\n",
      "4,/kaggle/input/traffic-signs-dataset-in-yolo-format/train.txt,3ed48dacf41e2918815eede88fa51153c243e71f8ef1f085cc815f055f5ae871\r\n",
      "5,/kaggle/input/traffic-signs-dataset-in-yolo-format/traffic-sign-to-test.mp4,8b94e9902d352d2720dbb1404d1b7db8ce1389870bb1ca262c4c8ac25a5084ad\r\n",
      "6,/kaggle/input/traffic-signs-dataset-in-yolo-format/classes.names,c0862a5b60cec96d0fda0ee6d5fe3bb33d6bd542fcae373c0aecb5351b91a085\r\n",
      "7,/kaggle/input/traffic-signs-dataset-in-yolo-format/yolov3_ts_test.cfg,01273b984ef1e32229e1ef804922dd8f58dd3c4d4ed2b4f077ceaefdf666c412\r\n",
      "8,/kaggle/input/traffic-signs-dataset-in-yolo-format/ts/ts/00266.jpg,8687839c4006131ecec2e5f9e89d40567ee7cc8d07b01eb5e4b899307b419ab6\r\n"
     ]
    }
   ],
   "source": [
    "# what does the output file look like?\n",
    "!head fileout.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cae125e",
   "metadata": {
    "papermill": {
     "duration": 0.002893,
     "end_time": "2024-11-06T10:55:19.203637",
     "exception": false,
     "start_time": "2024-11-06T10:55:19.200744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 513560,
     "sourceId": 1057373,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15.4568,
   "end_time": "2024-11-06T10:55:19.729666",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-06T10:55:04.272866",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
